{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PacktPublishing/Hands-On-Computer-Vision-with-Detectron2/blob/main/Chapter10/Detectron2_Chapter10_DataProcessing.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdT0qMST1SLK"
      },
      "source": [
        "# Chapter 10 - Data Processing\n",
        "\n",
        "## Download data\n",
        "Dataset Source: Cheng, Jun (2017): brain tumor dataset. figshare. Dataset. https://doi.org/10.6084/m9.figshare.1512427.v5 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# use this if the any of the next cell brings locale error (Python 3.9)\n",
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DwIFFLfBdUga"
      },
      "outputs": [],
      "source": [
        "!wget --quiet https://figshare.com/ndownloader/articles/1512427/versions/5 -O segbraintumors.zip\n",
        "data_folder = \"segbraintumors\"\n",
        "!unzip -q segbraintumors.zip -d {data_folder}\n",
        "\n",
        "sets = [\"1-766\", \"767-1532\", \"1533-2298\", \"2299-3064\"]\n",
        "sets = [\"brainTumorDataPublic_\"+_ for _ in sets]\n",
        "\n",
        "!unzip -q {data_folder}/{sets[0]}.zip -d {data_folder}\n",
        "!unzip -q {data_folder}/{sets[1]}.zip -d {data_folder}\n",
        "!unzip -q {data_folder}/{sets[2]}.zip -d {data_folder}\n",
        "!unzip -q {data_folder}/{sets[3]}.zip -d {data_folder}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yuaJFv4k1uxz"
      },
      "source": [
        "## Create COCO dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "oqRLeVzBGLbR"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "def create_headers():\n",
        "  data_json = {\n",
        "  \"info\":{\n",
        "    \"description\": \"Desc\"\n",
        "  },\n",
        "  \"licenses\":[{\n",
        "    \"id\":1,\n",
        "    \"url\":\"https://creativecommons.org/licenses/by/4.0/\",\n",
        "    \"name\":\"CC BY 4.0\"\n",
        "    }],\n",
        "  \"categories\":[\n",
        "    {\"id\":0,\"name\":\"tumors\",\"supercategory\":\"none\"},\n",
        "    {\"id\":1,\"name\":\"meningioma\",\"supercategory\":\"tumors\"},\n",
        "    {\"id\":2,\"name\":\"glioma\",\"supercategory\":\"tumors\"},\n",
        "    {\"id\":3,\"name\":\"pituitary\",\"supercategory\":\"tumors\"}\n",
        "    ],\n",
        "  \"images\": [],\n",
        "  \"annotations\":[]\n",
        "  }\n",
        "  return data_json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "A1tRLiRqFfcN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "def segmentation2bbox(segmentation):\n",
        "  segmentation = np.array(segmentation)\n",
        "  segmentation = segmentation.reshape((-1, 2))\n",
        "  x_min = segmentation[:, 0].min()\n",
        "  y_min = segmentation[:, 1].min()\n",
        "  x_max = segmentation[:, 0].max()\n",
        "  y_max = segmentation[:, 1].max()\n",
        "  width = x_max - x_min\n",
        "  height= y_max - y_min\n",
        "  bbox = [x_min, y_min, width, height]\n",
        "  return bbox\n",
        "\n",
        "def bbox2area(bbox):\n",
        "  return bbox[2]*bbox[3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "w2WJ291GI7Gy"
      },
      "outputs": [],
      "source": [
        "def create_image_obj(id, file_name, height, width):\n",
        "  return {\n",
        "      \"id\": id,\n",
        "      \"license\": 1,\n",
        "      \"file_name\": file_name,\n",
        "      \"height\": height,\n",
        "      \"width\": width\n",
        "  }\n",
        "\n",
        "def create_annotation_obj(id, \n",
        "                          image_id, \n",
        "                          category_id, \n",
        "                          segmentation, \n",
        "                          bbox):\n",
        "  iscrowd = 0\n",
        "  area = bbox2area(bbox)\n",
        "  return {\n",
        "      \"id\": id,\n",
        "      \"image_id\": image_id,\n",
        "      \"category_id\": int(category_id),\n",
        "      \"segmentation\": [segmentation.tolist()],\n",
        "      \"bbox\": bbox,\n",
        "      \"iscrowd\": iscrowd,\n",
        "      \"area\": area\n",
        "  }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KC1byjvpdwA6",
        "outputId": "085321d4-591b-4b71-c021-d41c9915eb2f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3064/3064 [00:33<00:00, 90.55it/s]\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import h5py\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "\n",
        "output_folder = data_folder+\"_coco\"\n",
        "os.makedirs(output_folder, exist_ok = True)\n",
        "data_json = create_headers()\n",
        "\n",
        "for i in tqdm(range(1, 3064+1)):\n",
        "  with h5py.File(f'{data_folder}/{i}.mat', 'r') as f:\n",
        "    obj = f['cjdata']\n",
        "    # Step 1: extract image and write it to file\n",
        "    image = obj['image'][:, :].astype('float64')\n",
        "    image = (image/image.max())*255.0\n",
        "    file_name = f\"{i}.jpg\"\n",
        "    cv2.imwrite(os.path.join(output_folder, file_name), image)\n",
        "    # Step 2: create JSON object for image and append it\n",
        "    height, width = image.shape[:2]\n",
        "    data_json[\"images\"].append(\n",
        "        create_image_obj(\n",
        "          id        = i, \n",
        "          file_name = file_name,\n",
        "          height    = height,\n",
        "          width     = width\n",
        "    ))\n",
        "\n",
        "    # Step 3: extract boundaries + labels then append them\n",
        "    label = obj['label'][:, :]\n",
        "    tumorBorder = obj['tumorBorder'][:, :]\n",
        "    for j, lbl in enumerate(label):\n",
        "      segmentation = tumorBorder[j].reshape((-1, 2))[:, [1, 0]].reshape((-1))\n",
        "      bbox = segmentation2bbox(segmentation)\n",
        "      data_json[\"annotations\"].append(\n",
        "          create_annotation_obj(\n",
        "            id            = i,\n",
        "            image_id      = i,\n",
        "            category_id   = lbl[0],\n",
        "            bbox          = bbox,\n",
        "            segmentation  = segmentation\n",
        "      ))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "l2Hb1KluaZbx"
      },
      "outputs": [],
      "source": [
        "af = \"_annotations.coco.json\"\n",
        "with open(os.path.join(output_folder, af), \"w\") as f:\n",
        "  json.dump(data_json, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIbcInoy1zdn"
      },
      "source": [
        "## Perform Train/Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "a0QbUOBP12Ks"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "def create_json(info, \n",
        "                licenses, \n",
        "                categories, \n",
        "                images, \n",
        "                annotations,\n",
        "                file_name):\n",
        "  obj = {\n",
        "      \"info\"        : info,\n",
        "      \"licenses\"    : licenses, \n",
        "      \"categories\"  : categories, \n",
        "      \"images\"      : images, \n",
        "      \"annotations\" : annotations\n",
        "  }\n",
        "  with open(file_name, \"w\") as f:\n",
        "    json.dump(obj, f)\n",
        "  print(f\"Saved {file_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ULl7gzrt18vZ"
      },
      "outputs": [],
      "source": [
        "name_ds = output_folder\n",
        "af = \"_annotations.coco.json\"\n",
        "with open(os.path.join(name_ds, af), \"r\") as f:\n",
        "  annotations_json = json.load(f)\n",
        "\n",
        "info        = annotations_json[\"info\"]\n",
        "licenses    = annotations_json[\"licenses\"]\n",
        "categories  = annotations_json[\"categories\"]\n",
        "images      = annotations_json[\"images\"]\n",
        "annotations = annotations_json[\"annotations\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "7gHphdl62IBS"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "stratify = [i['category_id'] for i in annotations]\n",
        "test_size = 0.1\n",
        "images_train, images_test, annotations_train, annotations_test = train_test_split(\n",
        "     images, \n",
        "     annotations,\n",
        "     test_size    = test_size,\n",
        "     stratify     = stratify,\n",
        "     random_state = 42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHIum-N02KwQ",
        "outputId": "55197832-536c-4fdc-f0bb-d92f64a98bff"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2757/2757 [00:00<00:00, 18698.62it/s]\n",
            "100%|██████████| 307/307 [00:00<00:00, 21451.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved segbraintumors_coco/train/_annotations.coco.json\n",
            "Saved segbraintumors_coco/test/_annotations.coco.json\n"
          ]
        }
      ],
      "source": [
        "import shutil\n",
        "from tqdm import tqdm\n",
        "train_path  = os.path.join(name_ds, \"train\")\n",
        "test_path   = os.path.join(name_ds, \"test\")\n",
        "train_af    = os.path.join(train_path, af)\n",
        "test_af     = os.path.join(test_path, af)\n",
        "\n",
        "os.makedirs(train_path, exist_ok=True)\n",
        "os.makedirs(test_path, exist_ok=True)\n",
        "\n",
        "# move images\n",
        "for img in tqdm(images_train):\n",
        "  frm = os.path.join(name_ds, img[\"file_name\"])\n",
        "  to  = train_path\n",
        "  shutil.move(frm, to)\n",
        "\n",
        "for img in tqdm(images_test):\n",
        "  frm = os.path.join(name_ds, img[\"file_name\"])\n",
        "  to  = test_path\n",
        "  shutil.move(frm, to)\n",
        "\n",
        "# write annotations\n",
        "create_json(info, \n",
        "            licenses, \n",
        "            categories, \n",
        "            images_train, \n",
        "            annotations_train,\n",
        "            file_name = train_af)\n",
        "create_json(info, \n",
        "            licenses, \n",
        "            categories, \n",
        "            images_test, \n",
        "            annotations_test,\n",
        "            file_name = test_af)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# workaround if the next cells bring locale error\n",
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "C5ZBR2e92LoK"
      },
      "outputs": [],
      "source": [
        "!rm {name_ds}/{af}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29-YjXmp48OP"
      },
      "source": [
        "## Download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "WQ3bdAmwbqCe"
      },
      "outputs": [],
      "source": [
        "!zip -q -r {name_ds}.zip {name_ds}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "TW5HL8Mfd6by",
        "outputId": "b3e6d2a8-9721-43c1-bf2a-99ca9ef19795"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_6d64f29b-3c11-42ef-b8d4-fa3096628f55\", \"segbraintumors_coco.zip\", 150433318)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download(f\"{name_ds}.zip\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4eniJchpBwW-"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyORj3iAEbjyIPQImu0caRhn",
      "include_colab_link": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.-1.-1"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
