{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyORj3iAEbjyIPQImu0caRhn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PacktPublishing/Hands-On-Computer-Vision-with-Detectron2/blob/main/Chapter12/Detectron2_Chapter12_Scripting.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 12 - Tracing versus Scripting"
      ],
      "metadata": {
        "id": "t5s_pJa4XnZD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a model"
      ],
      "metadata": {
        "id": "ammBoInhegKP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVeoI2c3ErWi",
        "outputId": "cef846a0-5b30-426f-d37e-990632f4e1f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SimplePyTorchModel(\n",
            "  (linear): Linear(in_features=4, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "device = \"cuda\"\n",
        "if not torch.cuda.is_available():\n",
        "  device = \"cpu\"\n",
        "\n",
        "class SimplePyTorchModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(SimplePyTorchModel, self).__init__()\n",
        "    self.linear = nn.Linear(4, 1)   \n",
        "    self.linear.weight.data.fill_(0.01)\n",
        "    self.linear.bias.data.fill_(0.01)\n",
        "\n",
        "  def forward(self, x):\n",
        "    y = self.linear(x)\n",
        "    if y.sum() > 0:\n",
        "      return y\n",
        "    else:\n",
        "      return -y\n",
        "\n",
        "pt_model = SimplePyTorchModel()\n",
        "pt_model.to(device)\n",
        "print(pt_model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for p in pt_model.parameters():\n",
        "  print(p.data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pd5lDNIemCn",
        "outputId": "9e3fccac-3b1e-4d07-a452-ee4687d211ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0100, 0.0100, 0.0100, 0.0100]], device='cuda:0')\n",
            "tensor([0.0100], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Perform Predictions"
      ],
      "metadata": {
        "id": "AZBT-XMPeiVE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.tensor(\n",
        "    data  = [[1, 2, 3, 4]], \n",
        "    dtype = torch.float32)\n",
        "X = X.to(device)\n",
        "with torch.no_grad():\n",
        "  y = pt_model(X)\n",
        "  print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1AfpXoxcuO_",
        "outputId": "e5168ce6-e841-4016-e81b-d52a5cc5cac6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1100]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save the model"
      ],
      "metadata": {
        "id": "qCSbu-fbQY8C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pt_model.to(\"cpu\")"
      ],
      "metadata": {
        "id": "l2yt7uULSjke",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "913710bd-45a9-408e-af32-3696d5b73d37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SimplePyTorchModel(\n",
              "  (linear): Linear(in_features=4, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(pt_model,\"pt_model.pt\")"
      ],
      "metadata": {
        "id": "_tpLxSfLQdwL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exporting to TorchScript using Tracing"
      ],
      "metadata": {
        "id": "Inwfpq8h5QQn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dummy_X = torch.tensor(\n",
        "    data  = [[-1, -2, -3, -4]], \n",
        "    dtype = torch.float32)\n",
        "traced_model = torch.jit.trace(\n",
        "    pt_model, \n",
        "    example_inputs = dummy_X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hmd3GZhILFdm",
        "outputId": "1dd3d6a3-b2a8-41ab-b9a5-6ecadae8523f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-1b0e76ddf8bf>:17: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if y.sum() > 0:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "traced_model.to(device)\n",
        "for p in traced_model.parameters():\n",
        "  print(p.data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGoE8US-7E6n",
        "outputId": "71241733-704d-4e00-cd3c-497fa1a162c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0100, 0.0100, 0.0100, 0.0100]], device='cuda:0')\n",
            "tensor([0.0100], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(traced_model.code)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_DwV33Sd7K43",
        "outputId": "b09e3824-dc9f-45ec-a46a-f7c1765a68e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "def forward(self,\n",
            "    x: Tensor) -> Tensor:\n",
            "  linear = self.linear\n",
            "  return torch.neg((linear).forward(x, ))\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test the exported model"
      ],
      "metadata": {
        "id": "Z6dq52CK6zul"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  y = traced_model(X)\n",
        "  print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZ2pnFhl6yko",
        "outputId": "f4ac6292-7abd-40c8-c391-d94b8f3840e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.1100]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Export to TorchScript using Scripting"
      ],
      "metadata": {
        "id": "sNpzRU1BKWSX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scripted_model = torch.jit.script(pt_model)\n",
        "print(scripted_model.code)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JuBKETfbLpZ5",
        "outputId": "00c0be5c-85e9-401f-fbbd-797c06e3aef2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "def forward(self,\n",
            "    x: Tensor) -> Tensor:\n",
            "  linear = self.linear\n",
            "  y = (linear).forward(x, )\n",
            "  if bool(torch.gt(torch.sum(y), 0)):\n",
            "    _0 = y\n",
            "  else:\n",
            "    _0 = torch.neg(y)\n",
            "  return _0\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for p in scripted_model.parameters():\n",
        "  print(p.data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojySQoWyKvkc",
        "outputId": "d723842b-12b3-44f1-bebd-8942811aefa1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0100, 0.0100, 0.0100, 0.0100]], device='cuda:0')\n",
            "tensor([0.0100], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scripted_model.to(device)\n",
        "with torch.no_grad():\n",
        "  y = scripted_model(X)\n",
        "  print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjQ3WIEELa7G",
        "outputId": "57e66cca-139e-4b00-9f63-671630afe9b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1100]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save the model"
      ],
      "metadata": {
        "id": "Q-UAvUOAM1n6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scripted_model.to(\"cpu\").save(\"scripted_model.pt\")"
      ],
      "metadata": {
        "id": "LnE3PFT_Ljod"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test loading"
      ],
      "metadata": {
        "id": "FHsFMaG6M25-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model = torch.jit.load(\"scripted_model.pt\")"
      ],
      "metadata": {
        "id": "Ckkjh_bTMzdJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for p in loaded_model.parameters():\n",
        "  print(p)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crGI2m4HM8gh",
        "outputId": "782d7310-3a4c-46ea-b411-2b214fe3211d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0100, 0.0100, 0.0100, 0.0100]], requires_grad=True)\n",
            "tensor([0.0100], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53oMvotFEE7z",
        "outputId": "60cdebb8-6ec0-40d2-fa41-1ffaa89dac4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RecursiveScriptModule(\n",
              "  original_name=SimplePyTorchModel\n",
              "  (linear): RecursiveScriptModule(original_name=Linear)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hL9Pe2JM_HA",
        "outputId": "0a50f361-4edd-445a-8dbe-156b700a66b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1100]], device='cuda:0', grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download model"
      ],
      "metadata": {
        "id": "-YderxeBNGzW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('scripted_model.pt')\n",
        "files.download('pt_model.pt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "mE8Db6DnNEfv",
        "outputId": "93e018de-e3f7-4df9-f9c3-9d3f336ae3fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_1a0989d5-eebc-4a19-aa88-feb05a9da6b2\", \"scripted_model.pt\", 3537)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_9f97d143-9f65-4ffa-9a70-83f24acc9f7b\", \"pt_model.pt\", 1643)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z0eqFmCCNPJt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}