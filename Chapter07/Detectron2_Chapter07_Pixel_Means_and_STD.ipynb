{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyORj3iAEbjyIPQImu0caRhn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PacktPublishing/Hands-On-Computer-Vision-with-Detectron2/blob/main/Chapter07/Detectron2_Chapter07_Pixel_Means_and_STD.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 06 - Pixel Means and Standard Deviations\n",
        "## The dataset\n",
        "Should execute the Notebook titled \"Data Processing\" first to process the dataset or run the following code to download the processed dataset from GitHub repository of the book."
      ],
      "metadata": {
        "id": "XS3qK692JBai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://github.com/PacktPublishing/Hands-On-Computer-Vision-with-Detectron2/raw/main/datasets/braintumors_coco.zip\n",
        "!unzip -q braintumors_coco.zip"
      ],
      "metadata": {
        "id": "8zILY3uiPB8P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35cb4f75-bf9b-42b8-c68b-04dae82b773c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "replace braintumors_coco/train/97 (2).jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing a data loader"
      ],
      "metadata": {
        "id": "GkePsvrIgOvk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "# Some configurations\n",
        "name_ds = \"braintumors_coco\"\n",
        "af = \"_annotations.coco.json\"\n",
        "img_dir = name_ds + \"/train/\"\n",
        "json_file_train = name_ds + \"/train/\" + af\n",
        "batch_size = 64\n",
        "num_workers = 2"
      ],
      "metadata": {
        "id": "_7KE9jhErqDQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TumorDataset(Dataset):\n",
        "  def __init__(self, \n",
        "                data,\n",
        "                img_dir=\"\",\n",
        "                transform = None):\n",
        "    self.data = data\n",
        "    self.img_dir = img_dir\n",
        "    self.transform = transform\n",
        "      \n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    file_name  = os.path.join(self.img_dir, \n",
        "                              self.data[idx]['file_name'])\n",
        "    image = cv2.imread(file_name)\n",
        "    if self.transform is not None:\n",
        "        image = self.transform(image = image)['image']\n",
        "    \n",
        "    return image"
      ],
      "metadata": {
        "id": "f00mNlIaCJvN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "image_size = 640\n",
        "augs = A.Compose([\n",
        "    A.Resize(height = image_size, width = image_size),\n",
        "    ToTensorV2()])"
      ],
      "metadata": {
        "id": "DRMp2gQskB3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "with open(json_file_train) as f:\n",
        "  ds = json.load(f)['images']\n",
        "\n",
        "tds = TumorDataset(ds, img_dir=img_dir, transform=augs)\n",
        "image_loader = DataLoader(tds, \n",
        "                          batch_size  = batch_size, \n",
        "                          shuffle     = False, \n",
        "                          num_workers = num_workers,\n",
        "                          pin_memory  = True)"
      ],
      "metadata": {
        "id": "bTSVuLkw-wy8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculate running means and standard deviations"
      ],
      "metadata": {
        "id": "znN7KM0Go80D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def broad_cast(x, image_size, channel):\n",
        "  y = torch.broadcast_to(x, (image_size**2, channel))\n",
        "  z = y.reshape(image_size, image_size, 3)\n",
        "  return torch.moveaxis(z, 2, 0)"
      ],
      "metadata": {
        "id": "9gW7h5YvqNts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RunningStats:\n",
        "  def __init__(self):\n",
        "    self.n = 0\n",
        "    self.mean = 0\n",
        "    self.ssd = 0 \n",
        "    \n",
        "  def push(self, x):\n",
        "    # start\n",
        "    dims = [0, 2, 3]\n",
        "    count = 1\n",
        "    for dim in dims:\n",
        "      count *= x.shape[dim]\n",
        "    image_size = x.shape[-1]\n",
        "    channel = x.shape[1]\n",
        "    if self.n == 0:\n",
        "      # start\n",
        "      new_mean = x.sum(axis=dims)/count\n",
        "      new_ssd = ((\n",
        "          x - broad_cast(\n",
        "                new_mean, \n",
        "                image_size, \n",
        "                channel\n",
        "                ))**2).sum(axis=dims)\n",
        "      new_count = count\n",
        "    else:\n",
        "      # old\n",
        "      old_count = self.n\n",
        "      old_mean = self.mean\n",
        "      old_ssd = self.ssd\n",
        "      old_sum = old_mean * old_count      \n",
        "      # new\n",
        "      new_count = self.n + count\n",
        "      new_sum = old_sum + x.sum(axis=dims)\n",
        "      new_mean = new_sum/(self.n + count)\n",
        "      \n",
        "      old_ssd_new_mean = (\n",
        "          old_ssd  \n",
        "          + 2*old_mean*old_sum\n",
        "          - old_count*(old_mean)**2\n",
        "          - 2*new_mean*old_sum\n",
        "          + old_count*(new_mean)**2\n",
        "          )\n",
        "      \n",
        "      new_ssd = (\n",
        "          old_ssd_new_mean + \n",
        "          (\n",
        "              (x - broad_cast(new_mean, \n",
        "                           image_size, \n",
        "                           channel))**2\n",
        "           ).sum(axis=dims))\n",
        "    # release results\n",
        "    self.mean = new_mean\n",
        "    self.ssd = new_ssd\n",
        "    self.n = new_count\n",
        "    self.std = torch.sqrt(new_ssd/(new_count-1))"
      ],
      "metadata": {
        "id": "oCAzgHOOTuG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rs = RunningStats()\n",
        "for inputs in tqdm(image_loader):\n",
        "  rs.push(inputs)\n",
        "\n",
        "print()\n",
        "print(rs.mean)\n",
        "print(rs.std)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbSv5KAfjZ_x",
        "outputId": "8bc8f0b4-12e1-40a7-8b23-ba9c1111e118"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 14/14 [00:32<00:00,  2.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "tensor([20.1962, 20.1962, 20.1962])\n",
            "tensor([39.5985, 39.5985, 39.5985])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "je55QFbIH45g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}