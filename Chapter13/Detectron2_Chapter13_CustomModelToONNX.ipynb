{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyORj3iAEbjyIPQImu0caRhn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PacktPublishing/Hands-On-Computer-Vision-with-Detectron2/blob/main/Chapter13/Detectron2_Chapter13_CustomModelToONNX.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installation"
      ],
      "metadata": {
        "id": "SaA2X5ec8n8A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOH4CMlj9P_P",
        "outputId": "bf648362-32ca-4a75-d4a4-68f0c87845b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.13.1+cu116\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WgBtpegxhW4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d23968c8-579f-4a03-8c12-f2d620f22974"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 KB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 KB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.1/154.1 KB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 KB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.6/96.6 KB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for detectron2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "flask 1.1.4 requires click<8.0,>=5.1, but you have click 8.1.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!python -m pip -qq install \\\n",
        "'git+https://github.com/facebookresearch/detectron2.git'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset"
      ],
      "metadata": {
        "id": "d31gTV2y0Ij7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://github.com/PacktPublishing/Hands-On-Computer-Vision-with-Detectron2/raw/main/datasets/braintumors_coco.zip\n",
        "!unzip -q braintumors_coco.zip"
      ],
      "metadata": {
        "id": "WgeTvjwg0KiK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get a predictor"
      ],
      "metadata": {
        "id": "1uuzLKdc-PTk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/PacktPublishing/Hands-On-Computer-Vision-with-Detectron2/raw/main/Chapter08/object_detector_hook.zip\n",
        "!unzip object_detector_hook.zip"
      ],
      "metadata": {
        "id": "o5COPf_G_8VV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc3edc86-3564-4c3c-be8a-f01845ee7ad0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-02-19 17:04:27--  https://github.com/PacktPublishing/Hands-On-Computer-Vision-with-Detectron2/raw/main/Chapter08/object_detector_hook.zip\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://media.githubusercontent.com/media/PacktPublishing/Hands-On-Computer-Vision-with-Detectron2/main/Chapter08/object_detector_hook.zip [following]\n",
            "--2023-02-19 17:04:27--  https://media.githubusercontent.com/media/PacktPublishing/Hands-On-Computer-Vision-with-Detectron2/main/Chapter08/object_detector_hook.zip\n",
            "Resolving media.githubusercontent.com (media.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to media.githubusercontent.com (media.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 307074938 (293M) [application/zip]\n",
            "Saving to: ‘object_detector_hook.zip’\n",
            "\n",
            "object_detector_hoo 100%[===================>] 292.85M   329MB/s    in 0.9s    \n",
            "\n",
            "2023-02-19 17:04:46 (329 MB/s) - ‘object_detector_hook.zip’ saved [307074938/307074938]\n",
            "\n",
            "Archive:  object_detector_hook.zip\n",
            "   creating: output/object_detector_hook/\n",
            "  inflating: output/object_detector_hook/events.out.tfevents.1672290421.5479d195d169.4549.0  \n",
            " extracting: output/object_detector_hook/last_checkpoint  \n",
            "  inflating: output/object_detector_hook/coco_instances_results.json  \n",
            "  inflating: output/object_detector_hook/cfg.pickle  \n",
            "  inflating: output/object_detector_hook/metrics.json  \n",
            " extracting: output/object_detector_hook/model_best.pth.zip  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_dir = \"output/object_detector_hook/\""
      ],
      "metadata": {
        "id": "D3RrND2xccPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip {output_dir}model_best.pth.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jH1yWVnTZWKg",
        "outputId": "cc6a18fe-ecac-411d-e6c9-761d0d126bf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  output/object_detector_hook/model_best.pth.zip\n",
            "  inflating: output/object_detector_hook/model_best.pth  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import detectron2\n",
        "import pickle\n",
        "with open(output_dir+\"cfg.pickle\", \"rb\") as f:\n",
        "  cfg = pickle.load(f)"
      ],
      "metadata": {
        "id": "uZpeMZM-Z_4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cfg.MODEL.WEIGHTS = output_dir+\"model_best.pth\"\n",
        "import torch\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "cfg.MODEL.DEVICE = device"
      ],
      "metadata": {
        "id": "s0ulgJ4zv1sk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.engine import DefaultPredictor\n",
        "predictor = DefaultPredictor(cfg)\n",
        "model = predictor.model"
      ],
      "metadata": {
        "id": "xkDfZqulxL-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.utils.logger import setup_logger\n",
        "logger = setup_logger()"
      ],
      "metadata": {
        "id": "NzOGlG2T3mcn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Some configurations\n",
        "name_ds = \"braintumors_coco\"\n",
        "name_ds_test = name_ds + \"_test\"\n",
        "image_root_test = name_ds + \"/test\"\n",
        "af = \"_annotations.coco.json\"\n",
        "json_file_test = name_ds + \"/test/\" + af\n",
        "from detectron2.data.datasets import register_coco_instances\n",
        "\n",
        "# register test dataset\n",
        "register_coco_instances(\n",
        "    name = name_ds_test,\n",
        "    metadata = {},\n",
        "    json_file = json_file_test,\n",
        "    image_root = image_root_test\n",
        "    )"
      ],
      "metadata": {
        "id": "Ztn6kdxS4BV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.data import (\n",
        "    build_detection_test_loader,\n",
        ")\n",
        "tld = build_detection_test_loader(cfg, cfg.DATASETS.TEST[0])\n",
        "tli = iter(tld)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kApCUqaRwzP7",
        "outputId": "4484c780-08e8-4f79-c249-8fd74b8dfa45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02/19 17:04:58 d2.data.datasets.coco]: Loaded 223 images in COCO format from braintumors_coco/test/_annotations.coco.json\n",
            "[02/19 17:04:58 d2.data.build]: Distribution of instances among all 2 categories:\n",
            "|  category  | #instances   |  category  | #instances   |\n",
            "|:----------:|:-------------|:----------:|:-------------|\n",
            "|  negative  | 154          |  positive  | 87           |\n",
            "|            |              |            |              |\n",
            "|   total    | 241          |            |              |\n",
            "[02/19 17:04:58 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "[02/19 17:04:58 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "[02/19 17:04:58 d2.data.common]: Serializing 223 elements to byte tensors and concatenating them all ...\n",
            "[02/19 17:04:58 d2.data.common]: Serialized dataset takes 0.06 MiB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model_inputs(tli):\n",
        "  inputs = next(tli)\n",
        "  inputs = [{\"image\": input[\"image\"] for input in inputs}]  \n",
        "  return inputs"
      ],
      "metadata": {
        "id": "9gsJX-81ADiE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dummy_inputs = get_model_inputs(tli)\n",
        "test_inputs = get_model_inputs(tli)"
      ],
      "metadata": {
        "id": "Hy9R49KR5Vvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ONNX"
      ],
      "metadata": {
        "id": "1kJXwv44k5Zh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Export"
      ],
      "metadata": {
        "id": "uCUxiwWY1spU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note opset_version: https://github.com/facebookresearch/detectron2/blob/main/detectron2/export/__init__.py#L19"
      ],
      "metadata": {
        "id": "Z0HOzBTgzxGG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.export import TracingAdapter\n",
        "wrapper = TracingAdapter(model, inputs=dummy_inputs)\n",
        "wrapper.eval()\n",
        "model_name = \"onnx_model.onnx\"\n",
        "\n",
        "with open(model_name, \"wb\") as f:\n",
        "  image = dummy_inputs[0][\"image\"]\n",
        "  torch.onnx.export(\n",
        "      model   = wrapper, \n",
        "      args    = (image,), \n",
        "      f       = f,\n",
        "      opset_version = 16\n",
        "      )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKf9GFKXjKe_",
        "outputId": "862731af-2505-4b6f-fca5-b72ada552c08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/detectron2/structures/image_list.py:85: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  assert t.shape[:-2] == tensors[0].shape[:-2], t.shape\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.8/dist-packages/detectron2/structures/boxes.py:151: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if tensor.numel() == 0:\n",
            "/usr/local/lib/python3.8/dist-packages/detectron2/structures/boxes.py:155: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  assert tensor.dim() == 2 and tensor.size(-1) == 4, tensor.size()\n",
            "/usr/local/lib/python3.8/dist-packages/detectron2/structures/boxes.py:151: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if tensor.numel() == 0:\n",
            "/usr/local/lib/python3.8/dist-packages/detectron2/structures/boxes.py:155: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  assert tensor.dim() == 2 and tensor.size(-1) == 4, tensor.size()\n",
            "/usr/local/lib/python3.8/dist-packages/detectron2/modeling/proposal_generator/proposal_utils.py:106: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if not valid_mask.all():\n",
            "/usr/local/lib/python3.8/dist-packages/detectron2/structures/boxes.py:191: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  assert torch.isfinite(self.tensor).all(), \"Box tensor contains infinite or NaN!\"\n",
            "/usr/local/lib/python3.8/dist-packages/detectron2/structures/boxes.py:192: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).\n",
            "  h, w = box_size\n",
            "/usr/local/lib/python3.8/dist-packages/detectron2/layers/nms.py:15: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  assert boxes.shape[-1] == 4\n",
            "/usr/local/lib/python3.8/dist-packages/torch/__init__.py:853: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  assert condition, message\n",
            "/usr/local/lib/python3.8/dist-packages/detectron2/layers/roi_align.py:55: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  assert rois.dim() == 2 and rois.size(1) == 5\n",
            "/usr/local/lib/python3.8/dist-packages/detectron2/modeling/roi_heads/fast_rcnn.py:138: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if not valid_mask.all():\n",
            "/usr/local/lib/python3.8/dist-packages/detectron2/structures/boxes.py:151: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if tensor.numel() == 0:\n",
            "/usr/local/lib/python3.8/dist-packages/detectron2/structures/boxes.py:155: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  assert tensor.dim() == 2 and tensor.size(-1) == 4, tensor.size()\n",
            "/usr/local/lib/python3.8/dist-packages/detectron2/structures/boxes.py:191: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  assert torch.isfinite(self.tensor).all(), \"Box tensor contains infinite or NaN!\"\n",
            "/usr/local/lib/python3.8/dist-packages/detectron2/structures/boxes.py:192: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).\n",
            "  h, w = box_size\n",
            "/usr/local/lib/python3.8/dist-packages/detectron2/modeling/roi_heads/fast_rcnn.py:155: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if num_bbox_reg_classes == 1:\n",
            "/usr/local/lib/python3.8/dist-packages/detectron2/layers/nms.py:15: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  assert boxes.shape[-1] == 4\n",
            "/usr/local/lib/python3.8/dist-packages/detectron2/structures/boxes.py:191: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  assert torch.isfinite(self.tensor).all(), \"Box tensor contains infinite or NaN!\"\n",
            "/usr/local/lib/python3.8/dist-packages/detectron2/structures/boxes.py:192: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).\n",
            "  h, w = box_size\n",
            "/usr/local/lib/python3.8/dist-packages/detectron2/structures/boxes.py:151: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if tensor.numel() == 0:\n",
            "/usr/local/lib/python3.8/dist-packages/detectron2/structures/boxes.py:155: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  assert tensor.dim() == 2 and tensor.size(-1) == 4, tensor.size()\n",
            "/usr/local/lib/python3.8/dist-packages/torch/onnx/_internal/jit_utils.py:258: UserWarning: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (Triggered internally at ../torch/csrc/jit/passes/onnx/shape_type_inference.cpp:1884.)\n",
            "  _C._jit_pass_onnx_node_shape_type_inference(node, params_dict, opset_version)\n",
            "/usr/local/lib/python3.8/dist-packages/torch/onnx/symbolic_opset9.py:5408: UserWarning: Exporting aten::index operator of advanced indexing in opset 16 is achieved by combination of multiple ONNX operators, including Reshape, Transpose, Concat, and Gather. If indices include negative values, the exported graph will produce incorrect results.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/ops/_register_onnx_ops.py:31: UserWarning: ROIAlign with aligned=True is not supported in ONNX, but will be supported in opset 16. The workaround is that the user need apply the patch https://github.com/microsoft/onnxruntime/pull/8564 and build ONNXRuntime from source.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torch/onnx/utils.py:687: UserWarning: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (Triggered internally at ../torch/csrc/jit/passes/onnx/shape_type_inference.cpp:1884.)\n",
            "  _C._jit_pass_onnx_graph_shape_type_inference(\n",
            "/usr/local/lib/python3.8/dist-packages/torch/onnx/utils.py:1178: UserWarning: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (Triggered internally at ../torch/csrc/jit/passes/onnx/shape_type_inference.cpp:1884.)\n",
            "  _C._jit_pass_onnx_graph_shape_type_inference(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Locale Error Fix\n",
        "May need this fix if running on GPU and cannot install onnx"
      ],
      "metadata": {
        "id": "L745CcuU1vwV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fix for locale error if cannot install onnx \n",
        "# due to locale error if running GPU runtime\n",
        "import locale\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding"
      ],
      "metadata": {
        "id": "Oz3Q3DVwoS_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_AP65XwlZhi",
        "outputId": "bc3c66cc-bf3a-4294-c4de-1d52228d2df5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting onnx\n",
            "  Downloading onnx-1.13.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m94.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.8/dist-packages (from onnx) (1.21.6)\n",
            "Collecting protobuf<4,>=3.20.2\n",
            "  Downloading protobuf-3.20.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.8/dist-packages (from onnx) (4.5.0)\n",
            "Installing collected packages: protobuf, onnx\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.19.6\n",
            "    Uninstalling protobuf-3.19.6:\n",
            "      Successfully uninstalled protobuf-3.19.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.11.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed onnx-1.13.0 protobuf-3.20.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load the model\n",
        "Load the exported model and check if it is well formed"
      ],
      "metadata": {
        "id": "FK9RGEvM14VW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check\n",
        "import onnx\n",
        "onnx_model = onnx.load(model_name)\n",
        "onnx.checker.check_model(onnx_model, True)"
      ],
      "metadata": {
        "id": "S0YIwMo3kznR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Execute the loaded model\n",
        "- Install onnxruntime\n",
        "- Create a run-time and execute the onnx loaded model"
      ],
      "metadata": {
        "id": "E5A2iqVl19n-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnxruntime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zr82M_GvhuV",
        "outputId": "8f1efd51-a20c-418e-9429-ad757574daa5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.14.0-cp38-cp38-manylinux_2_27_x86_64.whl (5.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m65.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from onnxruntime) (23.0)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.8/dist-packages (from onnxruntime) (23.1.21)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.8/dist-packages (from onnxruntime) (3.20.3)\n",
            "Collecting coloredlogs\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 KB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sympy in /usr/local/lib/python3.8/dist-packages (from onnxruntime) (1.7.1)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.8/dist-packages (from onnxruntime) (1.21.6)\n",
            "Collecting humanfriendly>=9.1\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 KB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.8/dist-packages (from sympy->onnxruntime) (1.2.1)\n",
            "Installing collected packages: humanfriendly, coloredlogs, onnxruntime\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.14.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import onnxruntime as ort\n",
        "ort_session = ort.InferenceSession(model_name)\n",
        "input_name = ort_session.get_inputs()[0].name"
      ],
      "metadata": {
        "id": "uX6zIShSpu2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = ort_session.run(\n",
        "    None,\n",
        "    {input_name: test_inputs[0][\"image\"].numpy()},\n",
        ")\n",
        "print(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61AntKVFlXdy",
        "outputId": "d1013b35-f88b-48cf-96f8-7fd1b970fd36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([[456.47223, 163.26727, 580.15924, 317.82056],\n",
            "       [456.27646, 154.84161, 584.78076, 311.30902],\n",
            "       [492.0383 , 161.29176, 578.70905, 254.3066 ],\n",
            "       [484.3123 , 161.73778, 575.2621 , 264.60254],\n",
            "       [451.01773, 200.97081, 546.3406 , 313.3496 ],\n",
            "       [461.3992 , 195.32011, 546.2074 , 306.30054]], dtype=float32), array([0, 1, 1, 0, 1, 0], dtype=int64), array([0.7608421 , 0.33609974, 0.17438626, 0.10448982, 0.08246013,\n",
            "       0.08060663], dtype=float32), array([800, 800], dtype=int64)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wrapper.outputs_schema(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7JIsg261dN9",
        "outputId": "f29d0b48-9003-44e0-caf6-1d29a77a8390"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'instances': Instances(num_instances=6, image_height=800, image_width=800, fields=[pred_boxes: Boxes(tensor([[456.4722, 163.2673, 580.1592, 317.8206],\n",
              "          [456.2765, 154.8416, 584.7808, 311.3090],\n",
              "          [492.0383, 161.2918, 578.7090, 254.3066],\n",
              "          [484.3123, 161.7378, 575.2621, 264.6025],\n",
              "          [451.0177, 200.9708, 546.3406, 313.3496],\n",
              "          [461.3992, 195.3201, 546.2074, 306.3005]])), pred_classes: [0 1 1 0 1 0], scores: [0.7608421  0.33609974 0.17438626 0.10448982 0.08246013 0.08060663]])}]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Validate prediction results\n",
        "Run prediction using the original model and compare the results"
      ],
      "metadata": {
        "id": "G6Yb_8TU2El1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictor.model(test_inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51on3PMtoh2K",
        "outputId": "81adb505-d055-44eb-c20a-519f593b831d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'instances': Instances(num_instances=6, image_height=800, image_width=800, fields=[pred_boxes: Boxes(tensor([[456.4723, 163.2672, 580.1592, 317.8206],\n",
              "          [456.2765, 154.8416, 584.7808, 311.3090],\n",
              "          [492.0383, 161.2917, 578.7090, 254.3066],\n",
              "          [484.3123, 161.7378, 575.2621, 264.6025],\n",
              "          [451.0178, 200.9709, 546.3406, 313.3496],\n",
              "          [461.3992, 195.3202, 546.2075, 306.3005]], device='cuda:0',\n",
              "         grad_fn=<IndexBackward0>)), scores: tensor([0.7608, 0.3361, 0.1744, 0.1045, 0.0825, 0.0806], device='cuda:0',\n",
              "         grad_fn=<IndexBackward0>), pred_classes: tensor([0, 1, 1, 0, 1, 0], device='cuda:0')])}]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jbYKqQWq1Wsu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}